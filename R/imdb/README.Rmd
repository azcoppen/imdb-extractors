---
title: "IMDB"
output:
  md_document:
    variant: markdown_github
---

[![Travis-CI Build Status](https://travis-ci.org/beanumber/imdb.svg?branch=master)](https://travis-ci.org/beanumber/imdb)

R package to load the IMDB into a SQL database. 

## Getting Started

`imdb` is a light package that leverages the the Python module [`IMDbPy`](https://github.com/alberanid/imdbpy) and the [`etl`](http://www.github.com/beanumber/etl) framework to make mirroring the IMDB in SQL painless, with user interaction taking place entirely within R. 

### Prerequisities

You must install the Python module [`IMDbPy`](http://imdbpy.sourceforge.net/), which also has external dependencies. For Ubuntu, the following command should install everything you need. Binaries for Mac OS X and Windows are available from the project's [Download](http://imdbpy.sourceforge.net/downloads.html) page. [You may want to consult the [.travis.yml](https://github.com/beanumber/imdb/blob/master/.travis.yml) file for a list of those dependencies.]

```{bash, eval=FALSE}
sudo apt-get install python-imdbpy python-sqlalchemy python-sqlobject python-psycopg2 python-mysqldb
```

You will also need to install the `etl` package from GitHub. 

```{r, message=FALSE, eval=FALSE}
install.packages("devtools")
devtools::install_github("beanumber/etl")
library(imdb)
```

### Installation

Similarly, `imdb` must be installed from GitHub.

```{r, message=FALSE, eval=FALSE}
devtools::install_github("beanumber/imdb")
library(imdb)
```

## Instantiate an object

Since the IMDB is very large (many gigabytes), it is best to store the data in a persistent SQL database. By default, `etl` will create an `RSQLite` for you in a temp directory -- but this is not a very safe place to store these data. Instead, we will connect to an existing (but empty) PostgreSQL database. 

```{r, eval=FALSE, message=FALSE}
if (require(RPostgreSQL)) {
  # must have pre-existing database "imdb_fresh"
  db <- src_postgres(host = "localhost", user = "postgres", password = "postgres", dbname = "imdb_fresh")
}
```

Since you will be downloading lots of data, you will probably want to specify a directory to store the raw data (which will take up several gigabytes on disk). Again, `etl` will create a directory for you if you don't, but that directory will be in a temp directory that is not safe. 

```{r, eval=FALSE}
imdb <- etl("imdb", db = db, dir = "~/dumps/imdb/")
```

## Performing the ETL steps

The first phase is to **E**xtract the data from IMDB. This may take a while. There are 49 files that take up approximately 2 GB on disk. By default, only the `movies`, `actors`, `actresses`, and `directors` files will be downloaded, but even these take up more then 500 MB of disk space. 

```{r, eval=FALSE}
imdb %>%
  etl_extract()
```

Mercifully, there is no **T**ransform phase for these data. However, the **L**oad phase can take a loooooong time. 

The load phase leverages the Python module `IMDbPy`, which also has external dependencies. Please see the [.travis.yml](https://github.com/beanumber/imdb/blob/master/.travis.yml) file for a list of those dependencies (on Ubuntu -- your configuration may be different). 

You may want to leave this running. To load the full set of files it took about 20 minutes and occupies about 9.5 gigabytes on disk. 

```{r, eval=FALSE}
imdb %>%
  etl_load()
```

```
# TIME TOTAL TIME TO INSERT/WRITE DATA : 21min, 13sec (wall) 20min, 59sec (user) 0min, 8sec (system)
```

```{bash, eval=FALSE}
sudo ls -lhS /var/lib/mysql/imdb
```

## Query the database

Once everything is completed, you can query your fresh copy of the IMDB.

```{r, eval=FALSE}
movies <- imdb %>%
  tbl("title")
movies %>%
  filter(title == "Star Wars")
```
